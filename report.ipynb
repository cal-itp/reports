{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from io import StringIO\n",
    "from calitp.tables import tbl\n",
    "from datetime import date, datetime\n",
    "from siuba import *\n",
    "from plotnine import *\n",
    "\n",
    "def friendly_date(x): \n",
    "    return datetime.strptime(x, \"%Y-%m-%d\").strftime(\"%b %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters",
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "DIR_PATH=\"2022/02/324\"\n",
    "\n",
    "#CALITP_ITP_ID = 10\n",
    "#CALITP_ITP_ID=45\n",
    "#CALITP_ITP_ID=269\n",
    "#CALITP_ITP_ID=108\n",
    "#CALITP_ITP_ID=106\n",
    "CALITP_ITP_ID=324\n",
    "CALITP_URL_NUMBER = 0\n",
    "DEBUG = False\n",
    "\n",
    "DATE_START = \"2022-02-01\"\n",
    "DATE_END = \"2022-02-28\"\n",
    "PUBLISH_DATE = \"2022-03-01\"\n",
    "\n",
    "CHANGE_PLOT_BREAKS = [\"Added\", \"Removed\", \"Unchanged\"]\n",
    "CHANGE_PLOT_VALUES = [\"#51BF9D\",\"#E16B26\", \"#8CBCCB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_TODAY=date.today()\n",
    "START_MONTH_DAY = friendly_date(DATE_START)\n",
    "END_MONTH_DAY = friendly_date(DATE_END)\n",
    "\n",
    "WEEK_MARKERS = pd.date_range(DATE_START, DATE_END, freq=\"W\").astype(str).tolist()\n",
    "BIWEEKLY_MARKERS = pd.date_range(DATE_START, DATE_END, freq=\"2W\").astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Convenience functions ----\n",
    "\n",
    "filter_start = filter(\n",
    "    _.calitp_extracted_at <= DATE_START,\n",
    "    _.calitp_deleted_at.fillna(\"2099-01-01\") > DATE_START,\n",
    ")\n",
    "\n",
    "filter_end = filter(\n",
    "    _.calitp_extracted_at <= DATE_END,\n",
    "    _.calitp_deleted_at.fillna(\"2099-01-01\") > DATE_END,\n",
    ")\n",
    "\n",
    "filter_itp = filter(\n",
    "    _.calitp_itp_id == CALITP_ITP_ID, _.calitp_url_number == CALITP_URL_NUMBER\n",
    ")\n",
    "\n",
    "def collect_to_dict(df):\n",
    "    \"\"\"Return the first row of a DataFrame as a dictionary.\n",
    "    \n",
    "    If there are no rows, then all dictionary values are None.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = collect(df)\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        return {k: None for k in result.columns}\n",
    "    # elif len(result) > 1:\n",
    "    #     raise ValueError(\"table contained more than 1 row\")\n",
    "    else:\n",
    "        return result.iloc[0,:].to_dict()\n",
    "\n",
    "\n",
    "select_rm_calitp = select(\n",
    "    -_.calitp_itp_id,\n",
    "    -_.calitp_url_number,\n",
    "    -_.calitp_hash,\n",
    "    -_.calitp_extracted_at,\n",
    "    -_.calitp_deleted_at,\n",
    ")\n",
    "\n",
    "def percent_format(labels):\n",
    "    return [\"{:.0f}%\".format(v*100) for v in labels]\n",
    "\n",
    "def query_id_changes(start_table, end_table, id_vars):\n",
    "    \"\"\"Calculate id variables that are removed, added, or unchanged between tables.\n",
    "    \n",
    "    It works by adding a special column to each table, performing a full join,\n",
    "    then checking where the special column is null.\n",
    "    \"\"\"\n",
    "    sym_id_vars = [_[k] for k in id_vars]\n",
    "\n",
    "    is_in_start = start_table >> select(*id_vars) >> mutate(is_in_start=True)\n",
    "    is_in_end = end_table >> select(*id_vars) >> mutate(is_in_end=True)\n",
    "\n",
    "    baseline = start_table >> count(*id_vars) >> rename(n_baseline=\"n\")\n",
    "    tallies = (\n",
    "        is_in_start\n",
    "        >> full_join(_, is_in_end, id_vars)\n",
    "        >> count(*sym_id_vars, _.is_in_start, _.is_in_end)\n",
    "        >> mutate(\n",
    "            status=case_when(\n",
    "                _,\n",
    "                {\n",
    "                    _.is_in_end.isna(): \"Removed\",\n",
    "                    _.is_in_start.isna(): \"Added\",\n",
    "                    True: \"Unchanged\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        >> count(*sym_id_vars[:-1], _.status)\n",
    "        >> group_by(*sym_id_vars[:-1])\n",
    "        >> mutate(percent=_.n / _.n.sum())\n",
    "    )\n",
    "\n",
    "    return tallies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Data ====\n",
    "# 1. High level feed info ----\n",
    "feed_info = (\n",
    "    tbl.gtfs_schedule_type2.feed_info()\n",
    "    >> filter_end\n",
    "    >> filter_itp\n",
    "    >> select_rm_calitp\n",
    "    >> pipe(collect_to_dict)\n",
    ")\n",
    "\n",
    "_n_routes = (\n",
    "    tbl.gtfs_schedule_type2.routes() >> filter_end >> filter_itp >> count() >> collect()\n",
    ")\n",
    "_n_stops = (\n",
    "    tbl.gtfs_schedule_type2.stops() >> filter_end >> filter_itp >> count() >> collect()\n",
    ")\n",
    "\n",
    "feed_info[\"n_routes\"] = int(_n_routes.loc[0, \"n\"])\n",
    "feed_info[\"n_stops\"] = int(_n_stops.loc[0, \"n\"])\n",
    "\n",
    "status = (\n",
    "    # note that dim feeds also now contains all feed_info information, but we've left in the\n",
    "    # gtfs_schedule_type2.feed_info table above. Could refactor and remove it in the future, and put\n",
    "    # all info in one table.\n",
    "    tbl.views.gtfs_schedule_dim_feeds()\n",
    "    >> filter(_.calitp_itp_id == CALITP_ITP_ID, _.calitp_url_number == CALITP_URL_NUMBER)\n",
    "    >> filter_end    \n",
    "    >> select(_.calitp_agency_name, _.gtfs_schedule_url == _.calitp_gtfs_schedule_url)\n",
    "    >> pipe(collect_to_dict)\n",
    ")\n",
    "\n",
    "# 2. Monthly metrics ----\n",
    "# Service hours per day. Note that the queried table calculates service\n",
    "# hours per service id, so we need to sum across service ids for the day\n",
    "_cross_cal = (\n",
    "    tbl.views.dim_date()\n",
    "    >> filter(_.full_date.between(DATE_START, DATE_END))\n",
    "    >> select(_.service_date == _.full_date)\n",
    ")\n",
    "\n",
    "tbl_daily_service_hours = (\n",
    "    tbl.views.gtfs_schedule_fact_daily_service()\n",
    "    >> filter_itp\n",
    "    >> filter(_.service_date.between(DATE_START, DATE_END))\n",
    "    >> right_join(_, _cross_cal, [\"service_date\"])\n",
    "    >> collect()\n",
    "    >> group_by(_.service_date)\n",
    "    >> summarize(\n",
    "        ttl_service_hours=(_.last_arrival_ts.max() - _.first_departure_ts.min()) / 3600,\n",
    "        ttl_service_hours2=_.ttl_service_hours.sum(),\n",
    "    )\n",
    "    >> mutate(\n",
    "        ttl_service_hours=_.ttl_service_hours.astype(float).round(2),\n",
    "        service_date=_.service_date.astype(\"datetime64[ns]\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# number of days where a feed did not have any trips in service\n",
    "n_days_no_service = (\n",
    "    tbl_daily_service_hours\n",
    "    >> filter(_.ttl_service_hours.isna())\n",
    "    >> pipe(lambda d: {\"n\": d.shape[0]})\n",
    ")\n",
    "\n",
    "# 3. Stop and Route ID Changes ----\n",
    "\n",
    "query_id_changes = (\n",
    "    # note that we remove these ids from the base fact table, since they are accessible via the\n",
    "    # join below, and will likely be removed from the table in the future.\n",
    "    select(-_.calitp_itp_id, -_.calitp_url_number)\n",
    "    >> filter(_.metric_period == \"month\")\n",
    "    >> inner_join(\n",
    "        _,\n",
    "        tbl.views.gtfs_schedule_dim_feeds() >> select(_.feed_key, _.calitp_itp_id, _.calitp_url_number),\n",
    "        \"feed_key\"\n",
    "    )\n",
    "    >> filter_itp \n",
    "    # note that metric dates for calendar type roll-ups (e.g. month, quarter) is the first day of the next\n",
    "    # period (e.g. metric date June 1st rolls up May).\n",
    "    >> filter(_.metric_date == PUBLISH_DATE)\n",
    "    >> rename(status = \"change_status\")\n",
    "    >> mutate(percent = _.n / _.n.sum())\n",
    "    >> collect()\n",
    ")\n",
    "\n",
    "tbl_stops_changed = tbl.views.gtfs_schedule_fact_stop_id_changes() >> query_id_changes\n",
    "tbl_routes_changed = tbl.views.gtfs_schedule_fact_route_id_changes() >> query_id_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# 4. Feed files being checked for ----\n",
    "\n",
    "file_categories = pd.DataFrame(\n",
    "    {\n",
    "        \"shapes.txt\": \"Visual display\",\n",
    "        \"pathways.txt\": \"Navigation\",\n",
    "        \"levels.txt\": \"Navigation\",\n",
    "        \"fare_rules.txt\": \"Fares\",\n",
    "        \"fare_leg_rules.txt\": \"Fares\",\n",
    "        \"feed_info.txt\": \"Technical contacts\",\n",
    "    }.items(),\n",
    "    columns=[\"name\", \"category\"],\n",
    ")\n",
    "\n",
    "importance = [\"Visual display\", \"Navigation\", \"Fares\", \"Technical contacts\"]\n",
    "\n",
    "tbl_file_check = (\n",
    "    tbl.gtfs_schedule_history.calitp_files_updates()\n",
    "    >> filter_itp\n",
    "    >> filter(_.calitp_extracted_at.isin(BIWEEKLY_MARKERS))\n",
    "    >> select(_.name, _.calitp_extracted_at)\n",
    "    >> collect()\n",
    "    >> right_join(_, file_categories, [\"name\"])\n",
    "    >> mutate(\n",
    "        calitp_extracted_at=_.calitp_extracted_at.fillna(\"missing\").astype(str),\n",
    "        success=\"✅\",\n",
    "    )\n",
    "    >> spread(_.calitp_extracted_at, _.success)\n",
    "    >> select(-_.missing)\n",
    "    >> arrange(_.category.apply(importance.index))\n",
    "    >> select(_.category, _.contains(\"\"))\n",
    "    >> pipe(_.fillna(\"\"))\n",
    ")\n",
    "\n",
    "# Analyze validation notices ----\n",
    "\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "tbl_biweekly = (\n",
    "    tbl.views.dim_date()\n",
    "    >> filter(_.full_date.isin(BIWEEKLY_MARKERS))\n",
    "    >> select(_.date == _.full_date)\n",
    ")\n",
    "\n",
    "tbl_validation_notices_raw = (\n",
    "    tbl.gtfs_schedule_type2.validation_notices()\n",
    "    >> filter_itp\n",
    "    >> inner_join(\n",
    "        _,\n",
    "        tbl_biweekly,\n",
    "        sql_on = (lambda lhs, rhs:\n",
    "                  (lhs.calitp_extracted_at <= rhs.date) &\n",
    "                  (func.coalesce(lhs.calitp_deleted_at, \"2099-01-01\") > rhs.date)\n",
    "        )\n",
    "    )\n",
    "    # do a simple count of the number of notices on each date\n",
    "    >> select(_.date, _.code, _.severity)\n",
    "    >> count(_.date, _.code, _.severity)\n",
    "    >> collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with correct columns and no rows\n",
    "_validation_empty = pd.DataFrame(\n",
    "    dict([(\"code\", []), (\"severity\", []), *zip(BIWEEKLY_MARKERS, [tuple()] * len(BIWEEKLY_MARKERS))])\n",
    ")\n",
    "\n",
    "# spread validation notices so dates are columns, and counts are values\n",
    "# TODO: when we spread the dates out, the counts sometimes can become floats,\n",
    "# so have decimals, which might look funky. We can fix this by either converting\n",
    "# the counts to strings before the code below\n",
    "if not tbl_validation_notices_raw.shape[0]:\n",
    "    _tbl_validation_notices = _validation_empty\n",
    "else:\n",
    "    out_wide = (\n",
    "        tbl_validation_notices_raw >> mutate(date=_.date.astype(str)) >> spread(_.date, _.n)\n",
    "    )\n",
    "    \n",
    "    _tbl_validation_notices = pd.concat(\n",
    "        [_validation_empty, out_wide], ignore_index=True\n",
    "    ).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame with correct columns and no rows\n",
    "_validation_severity_empty = pd.DataFrame(\n",
    "    dict([(\"code\", []), (\"severity\", []), *zip(BIWEEKLY_MARKERS, [tuple()] * len(BIWEEKLY_MARKERS))])\n",
    ")\n",
    "\n",
    "# spread validation notices so dates are columns, and counts are values\n",
    "# TODO: when we spread the dates out, the counts sometimes can become floats,\n",
    "# so have decimals, which might look funky. We can fix this by either converting\n",
    "# the counts to strings before the code below\n",
    "if not tbl_validation_notices_raw.shape[0]:\n",
    "    _tbl_validation_severity = _validation_severity_empty\n",
    "else:\n",
    "    out_wide = (\n",
    "        tbl_validation_notices_raw >> mutate(date=_.date.astype(str)) >> spread(_.date, _.n)\n",
    "    )\n",
    "    _tbl_validation_severity = pd.concat(\n",
    "        [_validation_severity_empty, out_wide], ignore_index=True\n",
    "    ).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl_code_descriptions = (\n",
    "    tbl.views.validation_code_descriptions()\n",
    "    >> select(_.code, _.human_readable_description)\n",
    "    >> collect()\n",
    "    # convert code to snakecase,\n",
    "    # note that this currently screws up cases like IO -> i_o\n",
    "    >> mutate(code = _.code.str.replace(r'(?<!^)(?=[A-Z])', '_').str.lower().str.replace(\"_notice$\", \"\"))\n",
    ")\n",
    "\n",
    "tbl_validation_notices_unfiltered = (\n",
    "    _tbl_validation_notices \n",
    "    >> inner_join(_, tbl_code_descriptions, [\"code\"])\n",
    "    >> select(_.code, _.human_readable_description, _.contains(\"\"))\n",
    "    #>> rename(error_name = _.code, error_description=_.human_readable_description)\n",
    ")\n",
    "\n",
    "tbl_validation_severity = (\n",
    "    _tbl_validation_severity\n",
    "    >> inner_join(_, tbl_code_descriptions,[\"code\"])\n",
    "    >> select(_.code, _.human_readable_description, _.severity)\n",
    "    >> collect()\n",
    ")\n",
    "\n",
    "# hackily remove float decimal values by casting to string and removing \".0\"\n",
    "# see https://stackoverflow.com/a/68693516/269834\n",
    "for col in tbl_validation_notices_unfiltered.columns[2:]:\n",
    "    tbl_validation_notices_unfiltered[col] = tbl_validation_notices_unfiltered[col].astype(str).apply(lambda x: x.replace('.0',''))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter tbl_validation for severity\n",
    "\n",
    "tbl_validation_notices = (\n",
    "    tbl_validation_notices_unfiltered\n",
    "    >> select(-_.severity)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "## Dump data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Note that everything is saved in this cell, except for plots,\n",
    "# which are saved in the cell they're defined in\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def to_rowspan_table(df, span_col):\n",
    "    d = df.to_dict(orient=\"split\")\n",
    "    row_span = df.groupby(span_col)[span_col].transform(\"count\")\n",
    "    not_first = df[span_col].duplicated()\n",
    "    \n",
    "    row_span[not_first] = 0\n",
    "    \n",
    "    d[\"rowspan\"] = row_span.tolist()\n",
    "    return d\n",
    "\n",
    "\n",
    "out_dir = Path(f\"outputs/{DIR_PATH}/data\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "json.dump(feed_info, open(out_dir / \"1_feed_info.json\", \"w\"))\n",
    "json.dump(status, open(out_dir / \"1_status.json\", \"w\"))\n",
    "\n",
    "tbl_daily_service_hours.to_json(\n",
    "    out_dir / \"2_daily_service_hours.json\", orient=\"records\"\n",
    ")\n",
    "json.dump(n_days_no_service, open(out_dir / \"2_n_days_no_service.json\", \"w\"))\n",
    "\n",
    "tbl_stops_changed.to_json(out_dir / \"3_stops_changed.json\", orient=\"records\")\n",
    "tbl_routes_changed.to_json(out_dir / \"3_routes_changed.json\", orient=\"records\")\n",
    "\n",
    "json.dump(to_rowspan_table(tbl_file_check, \"category\"), open(out_dir / \"4_file_check.json\", \"w\"))\n",
    "tbl_validation_severity.to_json(out_dir / \"4_validation_severity.json\", orient=\"split\")\n",
    "tbl_validation_notices.to_json(out_dir / \"5_validation_notices.json\", orient=\"split\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly GTFS Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(f\"\"\"\n",
    "Transit provider name: {feed_info[\"feed_publisher_name\"]}\n",
    "\n",
    "Date generated: {DATE_TODAY}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a monthly report, generated by the California Integrated Travel Project ([Cal-ITP](https://dot.ca.gov/cal-itp/cal-itp-gtfs)), summarizing issues discovered by [MobilityData](http://mobilitydata.io/)’s [GTFS Validator](https://github.com/MobilityData/gtfs-validator). This report is available for viewing by the general public to support continuous improvement of GTFS data and the experience of transit passengers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"\"\"\n",
    "Feed location: {status[\"gtfs_schedule_url\"]}\n",
    "\n",
    "Metrics for the most recent published version of the feed:\n",
    "\n",
    "* Date published: {feed_info[\"feed_version\"]}\n",
    "* Number of routes in any service: {feed_info[\"n_routes\"]}\n",
    "* Number of stops in service: {feed_info[\"n_stops\"]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Metrics for May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# Markdown(f\"\"\"\n",
    "# Days when the active feed was expired: {n_days_no_service[\"n\"]}\n",
    "# \"\"\")\n",
    "\n",
    "Markdown(f\"\"\"\n",
    "Days with no service hours: {n_days_no_service[\"n\"]}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    tbl_daily_service_hours\n",
    "    >> ggplot(aes(\"service_date\", \"ttl_service_hours2\"))\n",
    "    + geom_line()\n",
    "    + geom_point()\n",
    "    + theme_minimal(base_size=16)    \n",
    "    + theme(axis_text_x=element_text(angle=45, hjust=1))\n",
    "    + scale_x_datetime(date_breaks=\"1 week\")\n",
    "    + expand_limits(y=0)\n",
    "    + labs(\n",
    "        y = \"Total service hours\",\n",
    "        x = \"Service date\",\n",
    "        #title=\"Service hours per day\"\n",
    "    )\n",
    ")\n",
    "\n",
    "p.save(out_dir / \"2_service_hours.png\", width=4, height=4, dpi=300)\n",
    "#p.save(out_dir / \"2_service_hours.png\")\n",
    "\n",
    "p.draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes Since Previous Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siuba.dply.forcats import fct_rev\n",
    "\n",
    "p = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            tbl_stops_changed >> mutate(kind=\"Stops\"),\n",
    "            tbl_routes_changed >> mutate(kind=\"Routes\"),\n",
    "        ]\n",
    "    )\n",
    "    >> mutate(status = fct_rev(_.status))\n",
    "    >> ggplot(aes(\"kind\", \"n\", fill=\"status\"))\n",
    "    + geom_col()\n",
    "    + scale_fill_manual(limits = CHANGE_PLOT_BREAKS, values = CHANGE_PLOT_VALUES)\n",
    "    + labs(\n",
    "        x=\"GTFS schedule table\",\n",
    "        y=\"Number of IDs\",\n",
    "        title=f\"IDs Changed Between {START_MONTH_DAY} and {END_MONTH_DAY}\",\n",
    "    )\n",
    "    + theme_minimal()\n",
    "        + theme(legend_position=\"bottom\", legend_margin=30)\n",
    ")\n",
    "\n",
    "\n",
    "#p.save(out_dir / \"3_id_changes.png\")\n",
    "\n",
    "p.draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Alternative version using percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            tbl_stops_changed >> mutate(kind=\"Stops\"),\n",
    "            tbl_routes_changed >> mutate(kind=\"Routes\"),\n",
    "        ]\n",
    "    )\n",
    "    >> mutate(status = fct_rev(_.status))    \n",
    "    >> ggplot(aes(\"kind\", \"percent\", fill=\"status\"))\n",
    "    + geom_col()\n",
    "    + scale_fill_manual(limits = CHANGE_PLOT_BREAKS, values = CHANGE_PLOT_VALUES)\n",
    "    + labs(\n",
    "        x=\"GTFS schedule table\",\n",
    "        y=\"Percentage of IDs\",\n",
    "        #title=f\"IDs Changed Between {START_MONTH_DAY} and {END_MONTH_DAY}\",\n",
    "    )\n",
    "    + scale_y_continuous(labels=percent_format, breaks=np.arange(0, 1.2, 0.2))\n",
    "    + theme_minimal(base_size=16)\n",
    "    + theme(legend_position=\"bottom\", legend_margin=30)\n",
    ")\n",
    "\n",
    "p.save(out_dir / \"3_id_changes.png\", width=4, height=4, dpi=300)\n",
    "p.draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency with the [California GTFS Minimum Guidelines](https://dot.ca.gov/cal-itp/california-minimum-general-transit-feed-specification-gtfs-guidelines) for the feed downloaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the following files/fields exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_file_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Errors Observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_validation_severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tbl_validation_severity.shape[0] == 0:\n",
    "    display(Markdown(\"No validation error observed in your feed.\"))\n",
    "else:    \n",
    "    display(tbl_validation_severity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cal-ITP Validation Errors Observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_validation_notices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tbl_validation_notices.shape[0] == 0:\n",
    "    display(Markdown(\"No validation error observed in your feed.\"))\n",
    "else:    \n",
    "    display(tbl_validation_notices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about Cal-ITP, including the [Minimum GTFS Guidelines](https://dot.ca.gov/cal-itp/california-minimum-general-transit-feed-specification-gtfs-guidelines) and our [Transit Data Helpdesk](https://dot.ca.gov/programs/rail-and-mass-transportation/gtfs/helpdesk), contact [GTFSRT@dot.ca.gov](mailto:GTFSRT@dot.ca.gov)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
