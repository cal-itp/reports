{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from io import StringIO\n",
    "from calitp.tables import tbl\n",
    "from datetime import date, datetime\n",
    "from siuba import *\n",
    "from plotnine import *\n",
    "\n",
    "def friendly_date(x): \n",
    "    return datetime.strptime(x, \"%Y-%m-%d\").strftime(\"%b %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters",
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "DIR_PATH=\"2021/05/98\"\n",
    "\n",
    "CALITP_ITP_ID = 10\n",
    "#CALITP_ITP_ID=45\n",
    "CALITP_URL_NUMBER = 0\n",
    "DEBUG = False\n",
    "\n",
    "DATE_START = \"2021-05-01\"\n",
    "DATE_END = \"2021-06-01\"\n",
    "DATE_TODAY=date.today()\n",
    "START_MONTH_DAY = friendly_date(DATE_START)\n",
    "END_MONTH_DAY = friendly_date(DATE_END)\n",
    "\n",
    "WEEK_MARKERS = pd.date_range(DATE_START, DATE_END, freq=\"W\").astype(str).tolist()\n",
    "BIWEEKLY_MARKERS = pd.date_range(DATE_START, DATE_END, freq=\"2W\").astype(str).tolist()\n",
    "\n",
    "CHANGE_PLOT_BREAKS = [\"Added\", \"Removed\", \"Unchanged\"]\n",
    "CHANGE_PLOT_VALUES = [\"#51BF9D\",\"#E16B26\", \"#8CBCCB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Convenience functions ----\n",
    "\n",
    "filter_start = filter(\n",
    "    _.calitp_extracted_at <= DATE_START,\n",
    "    _.calitp_deleted_at.fillna(\"2099-01-01\") > DATE_START,\n",
    ")\n",
    "\n",
    "filter_end = filter(\n",
    "    _.calitp_extracted_at <= DATE_END,\n",
    "    _.calitp_deleted_at.fillna(\"2099-01-01\") > DATE_END,\n",
    ")\n",
    "\n",
    "filter_itp = filter(\n",
    "    _.calitp_itp_id == CALITP_ITP_ID, _.calitp_url_number == CALITP_URL_NUMBER\n",
    ")\n",
    "\n",
    "collect_to_dict = (\n",
    "    collect()\n",
    "    >> pipe(_.to_dict(orient=\"records\")[0])\n",
    ")\n",
    "\n",
    "\n",
    "select_rm_calitp = select(\n",
    "    -_.calitp_itp_id,\n",
    "    -_.calitp_url_number,\n",
    "    -_.calitp_hash,\n",
    "    -_.calitp_extracted_at,\n",
    "    -_.calitp_deleted_at,\n",
    ")\n",
    "\n",
    "def percent_format(labels):\n",
    "    return [\"{:.0f}%\".format(v*100) for v in labels]\n",
    "\n",
    "def query_id_changes(start_table, end_table, id_vars):\n",
    "    \"\"\"Calculate id variables that are removed, added, or unchanged between tables.\n",
    "    \n",
    "    It works by adding a special column to each table, performing a full join,\n",
    "    then checking where the special column is null.\n",
    "    \"\"\"\n",
    "    sym_id_vars = [_[k] for k in id_vars]\n",
    "\n",
    "    is_in_start = start_table >> select(*id_vars) >> mutate(is_in_start=True)\n",
    "    is_in_end = end_table >> select(*id_vars) >> mutate(is_in_end=True)\n",
    "\n",
    "    baseline = start_table >> count(*id_vars) >> rename(n_baseline=\"n\")\n",
    "    tallies = (\n",
    "        is_in_start\n",
    "        >> full_join(_, is_in_end, id_vars)\n",
    "        >> count(*sym_id_vars, _.is_in_start, _.is_in_end)\n",
    "        >> mutate(\n",
    "            status=case_when(\n",
    "                _,\n",
    "                {\n",
    "                    _.is_in_end.isna(): \"Removed\",\n",
    "                    _.is_in_start.isna(): \"Added\",\n",
    "                    True: \"Unchanged\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        >> count(*sym_id_vars[:-1], _.status)\n",
    "        >> group_by(*sym_id_vars[:-1])\n",
    "        >> mutate(percent=_.n / _.n.sum())\n",
    "    )\n",
    "\n",
    "    return tallies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Data ====\n",
    "# 1. High level feed info ----\n",
    "feed_info = (\n",
    "    tbl.gtfs_schedule_type2.feed_info()\n",
    "    >> filter_end\n",
    "    >> filter_itp\n",
    "    >> select_rm_calitp\n",
    "    >> collect_to_dict\n",
    ")\n",
    "\n",
    "_n_routes = (\n",
    "    tbl.gtfs_schedule_type2.routes() >> filter_end >> filter_itp >> count() >> collect()\n",
    ")\n",
    "_n_stops = (\n",
    "    tbl.gtfs_schedule_type2.stops() >> filter_end >> filter_itp >> count() >> collect()\n",
    ")\n",
    "\n",
    "feed_info[\"n_routes\"] = int(_n_routes.loc[0, \"n\"])\n",
    "feed_info[\"n_stops\"] = int(_n_stops.loc[0, \"n\"])\n",
    "\n",
    "status = (\n",
    "    tbl.views.gtfs_status_latest()\n",
    "    >> filter(_.itp_id == CALITP_ITP_ID, _.url_number == CALITP_URL_NUMBER)\n",
    "    >> select(-_.url_number, -_.status)\n",
    "    >> select_rm_calitp\n",
    "    >> collect_to_dict\n",
    ")\n",
    "\n",
    "# 2. Monthly metrics ----\n",
    "# Service hours per day. Note that the queried table calculates service\n",
    "# hours per service id, so we need to sum across service ids for the day\n",
    "_cross_cal = (\n",
    "    tbl.views.dim_date()\n",
    "    >> filter(_.full_date.between(DATE_START, DATE_END))\n",
    "    >> select(_.service_date == _.full_date)\n",
    ")\n",
    "\n",
    "tbl_daily_service_hours = (\n",
    "    tbl.views.gtfs_schedule_service_daily_metrics()\n",
    "    >> filter_itp\n",
    "    >> filter(_.service_date.between(DATE_START, DATE_END))\n",
    "    >> right_join(_, _cross_cal, [\"service_date\"])\n",
    "    >> collect()\n",
    "    >> group_by(_.service_date)\n",
    "    >> summarize(\n",
    "        ttl_service_hours=(_.last_arrival_ts.max() - _.first_departure_ts.min()) / 3600,\n",
    "        ttl_service_hours2=_.ttl_service_hours.sum(),\n",
    "    )\n",
    "    >> mutate(\n",
    "        ttl_service_hours=_.ttl_service_hours.astype(float).round(2),\n",
    "        service_date=_.service_date.astype(\"datetime64[ns]\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# number of days where a feed did not have any trips in service\n",
    "n_expired_days = (\n",
    "    tbl_daily_service_hours\n",
    "    >> filter(_.ttl_service_hours.isna())\n",
    "    >> pipe(lambda d: {\"n\": d.shape[0]})\n",
    ")\n",
    "\n",
    "# 3. Stop and Route ID Changes ----\n",
    "\n",
    "_tbl_stops_start = tbl.gtfs_schedule_type2.stops() >> filter_itp >> filter_start\n",
    "_tbl_stops_end = tbl.gtfs_schedule_type2.stops() >> filter_itp >> filter_end\n",
    "tbl_stops_changed = (\n",
    "    query_id_changes(_tbl_stops_start, _tbl_stops_end, [\"stop_id\"]) >> collect()\n",
    ")\n",
    "\n",
    "_tbl_routes_start = tbl.gtfs_schedule_type2.routes() >> filter_itp >> filter_start\n",
    "_tbl_routes_end = tbl.gtfs_schedule_type2.routes() >> filter_itp >> filter_end\n",
    "tbl_routes_changed = (\n",
    "    query_id_changes(_tbl_routes_start, _tbl_routes_end, [\"route_id\"]) >> collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# 4. Feed files being checked for ----\n",
    "\n",
    "file_categories = pd.DataFrame(\n",
    "    {\n",
    "        \"shapes.txt\": \"Visual display\",\n",
    "        \"pathways.txt\": \"Navigation\",\n",
    "        \"levels.txt\": \"Navigation\",\n",
    "        \"fare_rules.txt\": \"Fares\",\n",
    "        \"fare_leg_rules\": \"Fares\",\n",
    "        \"feed_info.txt\": \"Technical contacts\",\n",
    "    }.items(),\n",
    "    columns=[\"name\", \"category\"],\n",
    ")\n",
    "\n",
    "importance = [\"Visual display\", \"Navigation\", \"Fares\", \"Technical contacts\"]\n",
    "\n",
    "tbl_file_check = (\n",
    "    tbl.gtfs_schedule_history.calitp_files_updates()\n",
    "    >> filter_itp\n",
    "    >> filter(_.calitp_extracted_at.isin(BIWEEKLY_MARKERS))\n",
    "    >> select(_.name, _.calitp_extracted_at)\n",
    "    >> collect()\n",
    "    >> right_join(_, file_categories, [\"name\"])\n",
    "    >> mutate(\n",
    "        calitp_extracted_at=_.calitp_extracted_at.fillna(\"missing\").astype(str),\n",
    "        success=\"âœ…\",\n",
    "    )\n",
    "    >> spread(_.calitp_extracted_at, _.success)\n",
    "    >> select(-_.missing)\n",
    "    >> arrange(_.category.apply(importance.index))\n",
    "    >> select(_.category, _.contains(\"\"))\n",
    "    >> pipe(_.fillna(\"\"))\n",
    ")\n",
    "\n",
    "tbl_validation_notices = (\n",
    "    tbl.views.validation_notices()\n",
    "    >> filter_itp\n",
    "    >> filter(_.severity == \"ERROR\")\n",
    "    >> count(_.code, _.severity)\n",
    "    >> collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "## Dump data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Note that everything is saved in this cell, except for plots,\n",
    "# which are saved in the cell they're defined in\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def to_rowspan_table(df, span_col):\n",
    "    d = df.to_dict(orient=\"split\")\n",
    "    row_span = df.groupby(span_col)[span_col].transform(\"count\")\n",
    "    not_first = df[span_col].duplicated()\n",
    "    \n",
    "    row_span[not_first] = 0\n",
    "    \n",
    "    d[\"rowspan\"] = row_span.tolist()\n",
    "    return d\n",
    "\n",
    "\n",
    "out_dir = Path(f\"outputs/{DIR_PATH}/data\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "json.dump(feed_info, open(out_dir / \"1_feed_info.json\", \"w\"))\n",
    "json.dump(status, open(out_dir / \"1_status.json\", \"w\"))\n",
    "\n",
    "tbl_daily_service_hours.to_json(\n",
    "    out_dir / \"2_daily_service_hours.json\", orient=\"records\"\n",
    ")\n",
    "json.dump(n_expired_days, open(out_dir / \"2_n_expired_days.json\", \"w\"))\n",
    "\n",
    "tbl_stops_changed.to_json(out_dir / \"3_stops_changed.json\", orient=\"records\")\n",
    "tbl_routes_changed.to_json(out_dir / \"3_routes_changed.json\", orient=\"records\")\n",
    "\n",
    "json.dump(to_rowspan_table(tbl_file_check, \"category\"), open(out_dir / \"4_file_check.json\", \"w\"))\n",
    "tbl_validation_notices.to_json(out_dir / \"4_validation_notices.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly GTFS Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(f\"\"\"\n",
    "Transit provider name: {feed_info[\"feed_publisher_name\"]}\n",
    "\n",
    "Date generated: {DATE_TODAY}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a monthly report, generated by the California Integrated Travel Project ([Cal-ITP](https://dot.ca.gov/cal-itp/cal-itp-gtfs)), summarizing issues discovered by [MobilityData](http://mobilitydata.io/)â€™s [GTFS Validator](https://github.com/MobilityData/gtfs-validator). This report is available for viewing by the general public to support continuous improvement of GTFS data and the experience of transit passengers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"\"\"\n",
    "Feed location: {status[\"gtfs_schedule_url\"]}\n",
    "\n",
    "Metrics for the most recent published version of the feed:\n",
    "\n",
    "* Date published: {feed_info[\"feed_version\"]}\n",
    "* Number of routes in any service: {feed_info[\"n_routes\"]}\n",
    "* Number of stops in service: {feed_info[\"n_stops\"]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Metrics for May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# Markdown(f\"\"\"\n",
    "# Days when the active feed was expired: {n_expired_days[\"n\"]}\n",
    "# \"\"\")\n",
    "\n",
    "Markdown(f\"\"\"\n",
    "Days with no service hours: {n_expired_days[\"n\"]}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    tbl_daily_service_hours\n",
    "    >> ggplot(aes(\"service_date\", \"ttl_service_hours2\"))\n",
    "    + geom_line()\n",
    "    + geom_point()\n",
    "    + theme_minimal(base_size=16)    \n",
    "    + theme(axis_text_x=element_text(angle=45, hjust=1))\n",
    "    + scale_x_datetime(date_breaks=\"1 week\")\n",
    "    + expand_limits(y=0)\n",
    "    + labs(\n",
    "        y = \"Total service hours\",\n",
    "        x = \"Service date\",\n",
    "        #title=\"Service hours per day\"\n",
    "    )\n",
    ")\n",
    "\n",
    "p.save(out_dir / \"2_service_hours.png\", width=4, height=4, dpi=300)\n",
    "#p.save(out_dir / \"2_service_hours.png\")\n",
    "\n",
    "p.draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes Since Previous Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siuba.dply.forcats import fct_rev\n",
    "\n",
    "p = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            tbl_stops_changed >> mutate(kind=\"Stops\"),\n",
    "            tbl_routes_changed >> mutate(kind=\"Routes\"),\n",
    "        ]\n",
    "    )\n",
    "    >> mutate(status = fct_rev(_.status))\n",
    "    >> ggplot(aes(\"kind\", \"n\", fill=\"status\"))\n",
    "    + geom_col()\n",
    "    + scale_fill_manual(limits = CHANGE_PLOT_BREAKS, values = CHANGE_PLOT_VALUES)\n",
    "    + labs(\n",
    "        x=\"GTFS schedule table\",\n",
    "        y=\"Number of IDs\",\n",
    "        title=f\"IDs Changed Between {START_MONTH_DAY} and {END_MONTH_DAY}\",\n",
    "    )\n",
    "    + theme_minimal()\n",
    "        + theme(legend_position=\"bottom\", legend_margin=30)\n",
    ")\n",
    "\n",
    "\n",
    "#p.save(out_dir / \"3_id_changes.png\")\n",
    "\n",
    "p.draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Alternative version using percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            tbl_stops_changed >> mutate(kind=\"Stops\"),\n",
    "            tbl_routes_changed >> mutate(kind=\"Routes\"),\n",
    "        ]\n",
    "    )\n",
    "    >> mutate(status = fct_rev(_.status))    \n",
    "    >> ggplot(aes(\"kind\", \"percent\", fill=\"status\"))\n",
    "    + geom_col()\n",
    "    + scale_fill_manual(limits = CHANGE_PLOT_BREAKS, values = CHANGE_PLOT_VALUES)\n",
    "    + labs(\n",
    "        x=\"GTFS schedule table\",\n",
    "        y=\"Percentage of IDs\",\n",
    "        #title=f\"IDs Changed Between {START_MONTH_DAY} and {END_MONTH_DAY}\",\n",
    "    )\n",
    "    + scale_y_continuous(labels=percent_format, breaks=np.arange(0, 1.2, 0.2))\n",
    "    + theme_minimal(base_size=16)\n",
    "    + theme(legend_position=\"bottom\", legend_margin=30)\n",
    ")\n",
    "\n",
    "p.save(out_dir / \"3_id_changes.png\", width=4, height=4, dpi=300)\n",
    "p.draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency with the [California GTFS Minimum Guidelines](https://dot.ca.gov/cal-itp/california-minimum-general-transit-feed-specification-gtfs-guidelines) for the feed downloaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the following files/fields exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_file_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Errors Observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tbl_validation_notices.shape[0] == 0:\n",
    "    display(Markdown(\"No validation error observed in your feed.\"))\n",
    "else:    \n",
    "    display(tbl_validation_notices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about Cal-ITP, including the [Minimum GTFS Guidelines](https://dot.ca.gov/cal-itp/california-minimum-general-transit-feed-specification-gtfs-guidelines) and our [Transit Data Helpdesk](https://dot.ca.gov/programs/rail-and-mass-transportation/gtfs/helpdesk), contact [GTFSRT@dot.ca.gov](mailto:GTFSRT@dot.ca.gov)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-calitp-py",
   "language": "python",
   "name": "venv-calitp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
